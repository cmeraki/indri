{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052b10b-4853-4707-9452-b070ceeb5743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install llmcompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a72f3f-b991-449f-b209-96526ccccb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import Dataset\n",
    "\n",
    "from llmcompressor.transformers import SparseAutoModelForCausalLM, oneshot\n",
    "from llmcompressor.modifiers.quantization import QuantizationModifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e858fa-138f-421d-a441-d04be5eff86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"cmeraki/mimi_tts_hf_stage\"\n",
    "\n",
    "model = SparseAutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6c1f5-1d80-4190-8d7d-31f20161b9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = snapshot_download('cmeraki/quantization_data_sample', repo_type='dataset')\n",
    "quant_data = np.load(\n",
    "    Path(data_path, 'quantization_data_sample.npy')\n",
    ")\n",
    "\n",
    "print(quant_data.shape)\n",
    "\n",
    "num_samples, max_seq_len = 8192, 1024\n",
    "\n",
    "def create_dataset_from_tokens(token_array, tokenizer, num_samples=2048):\n",
    "    dataset_dict = {'text': [tokenizer.decode(d, skip_special_tokens=False) for d in tqdm(token_array)]}\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    dataset = dataset.shuffle().select(range(num_samples))\n",
    "    return dataset\n",
    "\n",
    "ds = create_dataset_from_tokens(quant_data, tokenizer, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067be498-3bf9-424c-8df2-0a0d38826849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recipe = QuantizationModifier(\n",
    "    targets=\"Linear\",\n",
    "    scheme=\"FP8\",\n",
    "    ignore=[\"lm_head\"],\n",
    ")quantization_config\n",
    "\n",
    "oneshot(\n",
    "  model=model,\n",
    "  dataset=ds,\n",
    "  recipe=recipe,\n",
    "  max_seq_length=max_seq_len,\n",
    "  num_calibration_samples=num_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b32b23-e1ec-4c4d-8d4c-61d79714a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(repo_id='cmeraki/indri-tts-775m-fp8')\n",
    "tokenizer.push_to_hub(repo_id='cmeraki/indri-tts-775m-fp8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a2062-58dc-43ee-8c0e-55a3bf35fcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
