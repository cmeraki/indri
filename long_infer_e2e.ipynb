{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de6684-28bf-4763-a649-83f97f2dacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from audiotoken import AudioToken, Tokenizers\n",
    "\n",
    "from tts.long_infer import AudioSemantic, normalize_text, generate_long\n",
    "from tts.infer import AudioSemantic as VanillaAudioSemantic\n",
    "from common import Config as cfg\n",
    "from common import ACOUSTIC, SEMANTIC, TEXT, ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec07f6e-1c9b-4401-ab62-5fe9dfbb23cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttslib = AudioSemantic()\n",
    "vanilla_ttslib = VanillaAudioSemantic()\n",
    "acoustic_tokenizer = AudioToken(Tokenizers.acoustic, device='cuda:0')\n",
    "semantic_tokenizer = AudioToken(Tokenizers.semantic_s, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb138b67-a944-47ea-95ce-07881e8ab9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_consecutive(arr):\n",
    "    mask = np.concatenate(([True], arr[1:] != arr[:-1]))\n",
    "    return arr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbeb8b4-244b-4924-8d00-99686254aa51",
   "metadata": {},
   "source": [
    "Prepare the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c89ab5-1e32-43f0-8044-07788535c6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt_aco_toks = acoustic_tokenizer.encode(Path('prompts/jenny_prompt.wav'))\n",
    "prompt_sem_toks = semantic_tokenizer.encode(Path('prompts/jenny_prompt.wav'))\n",
    "\n",
    "prompt_sem_toks = replace_consecutive(prompt_sem_toks[0][0])\n",
    "prompt_aco_toks.shape, prompt_sem_toks.shape\n",
    "\n",
    "flat_aco_toks = prompt_aco_toks[0, :2, :].clone()\n",
    "flat_aco_toks[1] += 1024\n",
    "flat_aco_toks = torch.stack([flat_aco_toks[0], flat_aco_toks[1]], dim=1).flatten()\n",
    "\n",
    "sa_prompt_toks_dict = {\n",
    "    'source_tokens': prompt_sem_toks.numpy(),\n",
    "    'target_tokens': flat_aco_toks.numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e416179-9f37-4bdc-83f7-f3c23959cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_aco_toks.shape, prompt_sem_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422bcaa-2771-4f86-b24a-9011a4645f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = acoustic_tokenizer.decode(prompt_aco_toks)\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27225a-26b3-4174-a6e3-0c3e6632505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_prompt_toks_dict = {\n",
    "    'source_tokens': np.array(ttslib.text_tokenizer.encode('said meg impatiently <period>')),\n",
    "    'target_tokens': prompt_sem_toks.numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060073a5-0fe4-4cc6-9811-a5dd225a5ede",
   "metadata": {},
   "source": [
    "Text to semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d135655-9aee-40b0-a48b-29c0738c8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"our adventure began in paris <period>\"\n",
    "txt2 = \"the eiffel tower amazed us <period>\"\n",
    "txt3 = \"we enjoyed cafes and croissants <period>\"\n",
    "txt4 = \"the louvres art was stunning <period>\"\n",
    "txt5 = \"we finally dived in a swimming pool <period>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440f97e-9704-4755-81ea-010c98d6f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"the breeze was gentle <comma> rustling the leaves of the trees <period>\"\n",
    "txt2 = \"it was a perfect evening to take a leisurely stroll <period>\"\n",
    "txt3 = \"every step on the gravel path felt like a soothing rhythm <period>\"\n",
    "txt4 = \"matching the tranquility of the surroundings <period>\"\n",
    "txt5 = \"as the sky shifted from orange to deep purple <period>\"\n",
    "txt6 = \"the first stars began to appear twinkling like tiny diamonds <period>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846030fd-ad7c-46e9-a74e-ba6f89755da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = vanilla_ttslib.text_to_semantic(txt1)\n",
    "a = vanilla_ttslib.semantic_to_audio(s)\n",
    "Audio(a[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0357227-2d3f-48b4-8fbe-e06f5bee42ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sem_toks_diff = []\n",
    "for t in [txt1, txt2, txt3, txt4, txt5]:\n",
    "    s, _, _ = generate_long(\n",
    "        model=ttslib.text_semantic_model,\n",
    "        source=TEXT,\n",
    "        target=SEMANTIC,\n",
    "        source_tokens=np.asarray(ttslib.text_tokenizer.encode(t)),\n",
    "        max_source_tokens=16,\n",
    "        source_overlap=8,\n",
    "        device='cuda:0',\n",
    "        temperature=0.8,\n",
    "        prompt_dict=ts_prompt_toks_dict\n",
    "    )\n",
    "    sem_toks_diff.extend(s)\n",
    "    print(s.shape, replace_consecutive(s).shape)\n",
    "    aud = vanilla_ttslib.semantic_to_audio(s)\n",
    "    display(Audio(aud[0], rate=24000))\n",
    "\n",
    "sem_toks_diff = np.array(sem_toks_diff)\n",
    "sem_toks_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0906a43-135e-4a9f-9fc1-072b92149d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = ' '.join([txt1, txt2, txt3])\n",
    "sentence_tokens = np.asarray(ttslib.text_tokenizer.encode(sentences))\n",
    "\n",
    "sem_toks, st, gt = generate_long(\n",
    "    model=ttslib.text_semantic_model,\n",
    "    source=TEXT,\n",
    "    target=SEMANTIC,\n",
    "    source_tokens=sentence_tokens,\n",
    "    max_source_tokens=16,\n",
    "    source_overlap=8,\n",
    "    device='cuda:0',\n",
    "    temperature=0.8,\n",
    "    prompt_dict=ts_prompt_toks_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2fa3e-e10d-4e07-b9a0-425045c0be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sem_toks)\n",
    "plt.hist(sem_toks_diff, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bb0f0-4987-4c65-8cd9-c4fd38842e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auds = []\n",
    "\n",
    "for i in range(0, sem_toks_diff.shape[-1], 150):\n",
    "    start_idx = i\n",
    "    end_idx = i + 150\n",
    "    try:\n",
    "        print(start_idx, end_idx)\n",
    "        aud = vanilla_ttslib.semantic_to_audio(sem_toks_diff[start_idx: end_idx])\n",
    "        print(aud.shape)\n",
    "        auds.append(aud)\n",
    "        display(Audio(aud[0], rate=24000))\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48234fc-353f-4974-9f96-d67b58fa0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = vanilla_ttslib.semantic_to_audio(sem_toks_diff[300:])\n",
    "display(Audio(aud[0], rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35170c-0792-45e5-90fa-07dd555821e7",
   "metadata": {},
   "source": [
    "Semantic to acoustic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e216e5-b11a-4903-aa75-812dcaa73889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acoustic_tokens, st, gt = generate_long(\n",
    "    model=ttslib.semantic_acoustic_model,\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC,\n",
    "    source_tokens=sem_toks_diff,\n",
    "    device='cuda:0',\n",
    "    temperature=0.9,\n",
    "    top_k=50,\n",
    "    max_source_tokens=128,\n",
    "    source_overlap=64,\n",
    "    prompt_dict=sa_prompt_toks_dict\n",
    ")\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372a062-0650-4569-b64c-72e94fcbd638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "display(Audio(wav[0].cpu().numpy(), rate=24000))\n",
    "\n",
    "auds = acoustic_tokenizer.decode(prompt_aco_toks)\n",
    "display(Audio(auds[0], rate=24000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07354105-88a7-4760-9240-fd08ed4ba0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81568d53-9e2c-4ea8-9bcb-fae581f4fde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6369f-66e2-4806-9b78-e020568494c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = st[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba344c1-8d69-46f2-85fe-02947d419775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_sem = (x[0, :128] - cfg.OFFSET[SEMANTIC])\n",
    "temp_aco = vanilla_ttslib.semantic_to_audio(temp_sem.cpu().numpy())\n",
    "Audio(temp_aco[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec54b7-a5af-4d61-ac9f-009f369baceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = gt[1] - cfg.OFFSET[ACOUSTIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c1bd6-1ae1-4f0c-9b2e-f04638271f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z[::2] > 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989c69f-0c82-4e38-a07f-c1d460e68cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d0b82-3c48-4bbf-820b-8f1cceb754f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48756eaa-5ab3-4810-abc1-4a43d002a7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
