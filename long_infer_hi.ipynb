{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef148c5-ab4d-499b-9651-c2e1e907dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Audio\n",
    "from audiotoken import AudioToken, Tokenizers\n",
    "\n",
    "from tts.long_infer import AudioSemantic\n",
    "from common import Config as cfg\n",
    "from common import ACOUSTIC, SEMANTIC, ctx\n",
    "from tts.long_infer import generate as aco_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d12e3-8d1c-42e9-aae3-e379bfe24dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttslib = AudioSemantic()\n",
    "acoustic_tokenizer = AudioToken(Tokenizers.acoustic, device='cuda:0')\n",
    "semantic_tokenizer = AudioToken(Tokenizers.semantic_s, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd630cda-dc14-4fc1-9084-519368bdfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_consecutive(arr):\n",
    "    mask = np.concatenate(([True], arr[1:] != arr[:-1]))\n",
    "    return arr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5cc98-4550-4660-8342-c4b3c0777144",
   "metadata": {},
   "source": [
    "- Generate semantic tokens of the prompt\n",
    "- Use ttslib to generate corresponding acoustic tokens of 2 codebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c193c7c-1fda-4965-a162-2b6b54f1a3e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aco_toks = acoustic_tokenizer.encode(Path('female_prompt_short.wav'))\n",
    "sem_toks = semantic_tokenizer.encode(Path('female_prompt_short.wav'))\n",
    "\n",
    "sem_toks = replace_consecutive(sem_toks[0][0])\n",
    "aco_toks.shape, sem_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3871aa-2c58-4e56-ba06-4cfd3893f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = acoustic_tokenizer.decode(aco_toks[:, :, :150])\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2225e-1eb9-4074-98b1-55cc20047418",
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_gen_toks = aco_generate(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=sem_toks[:64].numpy(),\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC\n",
    ")\n",
    "aco_gen_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b1ccd-c6d0-46ed-a248-1b9fc1d1a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation from original semantic tokens\n",
    "auds = ttslib.semantic_to_audio(sem_toks.numpy())\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de4ca8-ce1a-4335-b0c8-7742b704a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation from intermediatery 2 codebook\n",
    "auds = ttslib.acoustic_tokenizer.decode(torch.tensor(aco_gen_toks))\n",
    "Audio(auds[0], rate=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3201bb3-aa51-485f-bb3e-03954b3e5de4",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a476b-a64d-406d-aecd-ede461e13bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"my name is romit <comma> and i am trying to build indri <period>\"\n",
    "txt2 = \"the breeze was gentle <comma> rustling the leaves of the trees as birds chirped softly in the distance <period>\"\n",
    "txt3 = \"it was a perfect evening to take a leisurely stroll <comma> letting the calmness of nature wash over you <period>\"\n",
    "txt4 = \"every step on the gravel path felt like a soothing rhythm <comma> matching the tranquility of the surroundings <period>\"\n",
    "txt5 = \"as the sky shifted from orange to deep purple <comma> the first stars began to appear <comma> twinkling like tiny diamonds in the vastness above <period>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c254cd-f622-4ef3-8964-e551f921f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks = ttslib.text_to_semantic(' '.join([txt1, txt2, txt3]))\n",
    "print(sem_toks.shape, np.unique(sem_toks).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea36aed-cb78-4a2a-8a67-89e2d55a2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks_diff = [ttslib.text_tokenizer.encode(t) for t in [txt1, txt2, txt3, txt4, txt5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92f8f-4840-481f-9f6d-dea9f42a1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(s) for s in sem_toks_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1728b6-ea6d-46bd-9aca-8b81e9f1e631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, t in enumerate([txt1, txt2, txt3, txt4, txt5]):\n",
    "    try:\n",
    "        s = ttslib.text_to_semantic(t)\n",
    "        print(s.shape)\n",
    "        aud = ttslib.semantic_to_audio(s)\n",
    "        print(aud.shape)\n",
    "        display(Audio(aud[0], rate=24000))\n",
    "    except Exception as err:\n",
    "        print(f'err at {idx}, {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8ca9c-d0b6-4dbd-8ec6-44e6fd6438d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auds = []\n",
    "\n",
    "for i in range(5):\n",
    "    try:\n",
    "        aud = ttslib.semantic_to_audio(sem_toks[100:300])\n",
    "        print(aud.shape)\n",
    "        auds.append(aud)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "for aud in auds:\n",
    "    display(Audio(aud[0], rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc462de1-6ca5-4eb2-bc62-8ecd6c02fc9f",
   "metadata": {},
   "source": [
    "legacy gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcf145-d48f-4360-a0fa-d8142c62de4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auds = []\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        aud = ttslib.semantic_to_audio_long(sem_toks)\n",
    "        print(aud.shape)\n",
    "        auds.append(aud)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168b3be-a0bf-47cc-8190-4d92cb9e1af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for aud in auds:\n",
    "    display(Audio(aud[0], rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31540c8-d996-4845-a5bf-99cf9389d49a",
   "metadata": {},
   "source": [
    "new gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70c4c6-b92d-47ec-85f3-812e5edc8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new(model, source, target, source_tokens, device):\n",
    "    source_tokens = source_tokens + cfg.OFFSET[source]\n",
    "    max_source_tokens = cfg.max_source_tokens//2\n",
    "\n",
    "    source_overlap = 64\n",
    "    target_overlap = 0\n",
    "    source_stride = max_source_tokens - source_overlap\n",
    "\n",
    "    # Initialize as empty\n",
    "    target_tokens = np.asarray([])\n",
    "\n",
    "    print(\n",
    "        f'Source, tokens shape: {source_tokens.shape}, overlap: {source_overlap}, stride: {source_stride}, max tokens: {max_source_tokens}'\n",
    "    )\n",
    "\n",
    "    for idx in range(0, len(source_tokens), source_stride):\n",
    "        end_idx = idx + max_source_tokens\n",
    "        source_cut = source_tokens[idx: end_idx]\n",
    "        target_cut = target_tokens[-target_overlap:]\n",
    "\n",
    "        input_tokens = np.hstack([\n",
    "            source_cut,\n",
    "            cfg.INFER_TOKEN[target],\n",
    "            target_cut\n",
    "        ])\n",
    "\n",
    "        input_tokens = torch.tensor(input_tokens, dtype=torch.long, device=device)[None, ...]\n",
    "\n",
    "        print(f'Source tokens shape: {input_tokens.shape}, start idx: {idx}, end idx: {end_idx}')\n",
    "        print(f'Target cut shape: {target_cut.shape}, overlap: {target_overlap}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with ctx:\n",
    "                new_target_tokens = model.generate(\n",
    "                    input_tokens,\n",
    "                    1024,\n",
    "                    temperature=0.8,\n",
    "                    top_k=100,\n",
    "                    stop_token=cfg.STOP_TOKEN[target]\n",
    "                ).detach().cpu().numpy()[0]\n",
    "                print(f'Gen shape: {new_target_tokens.shape}')\n",
    "\n",
    "        new_target_tokens = new_target_tokens[input_tokens.shape[-1]:]\n",
    "\n",
    "        # Update the target overlap ratio, for x toks, we generate y toks\n",
    "        num_source_new_toks = end_idx-idx\n",
    "        if idx:\n",
    "            num_source_new_toks = end_idx-idx-source_overlap\n",
    "        target_overlap = source_overlap * new_target_tokens.shape[-1]/num_source_new_toks\n",
    "        target_overlap = math.ceil(target_overlap)\n",
    "        print(f'Source toks: {num_source_new_toks}, New target shape: {new_target_tokens.shape}, overlap: {target_overlap}')\n",
    "        # Merge into existing target tokens\n",
    "        target_tokens = np.hstack([target_tokens, new_target_tokens])\n",
    "        print(f'Overall target shape: {target_tokens.shape}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    target_tokens = target_tokens - cfg.OFFSET[target]\n",
    "    return target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d268051-a99e-41f3-b651-bc022285a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_aco_toks = aco_toks[0, :2, :]\n",
    "prompt_aco_toks[1] += 1024\n",
    "prompt_aco_toks = torch.stack([prompt_aco_toks[0], prompt_aco_toks[1]], dim=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcc52e-d016-4f92-a1b3-3efec03eacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_toks_dict = {\n",
    "    'source_tokens': sem_toks.numpy(),\n",
    "    'target_tokens': prompt_aco_toks.numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc6e20-627e-45ef-b8c0-85935efa3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_prompt(model, source, target, source_tokens, prompt_dict, device):\n",
    "    source_tokens = source_tokens + cfg.OFFSET[source]\n",
    "    max_source_tokens = cfg.max_source_tokens//2\n",
    "\n",
    "    prompt_source_tokens = prompt_toks_dict.get('source_tokens')\n",
    "    prompt_target_tokens = prompt_toks_dict.get('target_tokens')\n",
    "    print(f'Prompt source tokens: {prompt_source_tokens.shape}, prompt target tokens: {prompt_target_tokens.shape}')\n",
    "\n",
    "    source_overlap = 64\n",
    "    target_overlap = 0\n",
    "    source_stride = max_source_tokens - source_overlap\n",
    "\n",
    "    # Initialize as empty\n",
    "    target_tokens = np.asarray([])\n",
    "\n",
    "    print(\n",
    "        f'Source, tokens shape: {source_tokens.shape}, overlap: {source_overlap}, stride: {source_stride}, max tokens: {max_source_tokens}'\n",
    "    )\n",
    "\n",
    "    for idx in range(0, len(source_tokens), source_stride):\n",
    "        end_idx = idx + max_source_tokens\n",
    "        source_cut = source_tokens[idx: end_idx]\n",
    "        target_cut = target_tokens[-target_overlap:]\n",
    "\n",
    "        input_tokens = np.hstack([\n",
    "            source_cut,\n",
    "            cfg.INFER_TOKEN[target],\n",
    "            target_cut\n",
    "        ])\n",
    "\n",
    "        if idx == 0:\n",
    "            input_tokens = np.hstack([\n",
    "                prompt_source_tokens,\n",
    "                source_cut,\n",
    "                cfg.INFER_TOKEN[target],\n",
    "                prompt_target_tokens,\n",
    "                target_cut\n",
    "            ])\n",
    "\n",
    "        input_tokens = torch.tensor(input_tokens, dtype=torch.long, device=device)[None, ...]\n",
    "\n",
    "        print(f'Source tokens shape: {input_tokens.shape}, start idx: {idx}, end idx: {end_idx}')\n",
    "        print(f'Target cut shape: {target_cut.shape}, overlap: {target_overlap}')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with ctx:\n",
    "                new_target_tokens = model.generate(\n",
    "                    input_tokens,\n",
    "                    1024,\n",
    "                    temperature=0.8,\n",
    "                    top_k=100,\n",
    "                    stop_token=cfg.STOP_TOKEN[target]\n",
    "                ).detach().cpu().numpy()[0]\n",
    "                print(f'Gen shape: {new_target_tokens.shape}')\n",
    "\n",
    "        new_target_tokens = new_target_tokens[input_tokens.shape[-1]:]\n",
    "\n",
    "        # Update the target overlap ratio, for x toks, we generate y toks\n",
    "        num_source_new_toks = end_idx-idx\n",
    "        if idx:\n",
    "            num_source_new_toks = end_idx-idx-source_overlap\n",
    "        target_overlap = source_overlap * new_target_tokens.shape[-1]/num_source_new_toks\n",
    "        target_overlap = math.ceil(target_overlap)\n",
    "        print(f'Source toks: {num_source_new_toks}, New target shape: {new_target_tokens.shape}, overlap: {target_overlap}')\n",
    "        # Merge into existing target tokens\n",
    "        target_tokens = np.hstack([target_tokens, new_target_tokens])\n",
    "        print(f'Overall target shape: {target_tokens.shape}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    target_tokens = target_tokens - cfg.OFFSET[target]\n",
    "    return target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fdf55-e73c-42fb-9e71-bbd190b23b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acoustic_tokens = gen_new_prompt(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=sem_toks,\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC,\n",
    "    prompt_dict=prompt_toks_dict,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1526065-6703-4321-9f95-191cf9c4ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens[:-1]))\n",
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "Audio(wav[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e639ba-5c93-42f1-8ec7-59173f9baca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cc303-9d60-4da1-b63b-06f2a9c7be8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acoustic_tokens = gen_new(\n",
    "    model=ttslib.semantic_acoustic_model, \n",
    "    source_tokens=sem_toks,\n",
    "    source=SEMANTIC,\n",
    "    target=ACOUSTIC,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print(acoustic_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48a123-d3e1-494a-8415-ccb50402f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = ttslib.acoustic_tokenizer.decode(torch.tensor(acoustic_tokens))\n",
    "Audio(wav[0], rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724a59c-29ab-42ec-ad8f-b989b473a454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
